---
marp: true
---

# Building Effective Agents
A Journey from Prototyping to Production

---

_Depois de testar v√°rios frameworks de LLM chains e agentes e ter construindo produtos de IA de verdade, **percebi que quase ningu√©m usa esses frameworks em produ√ß√£o.**_

_As aplica√ß√µes de IA que funcionam bem costumam ser feitas com c√≥digo pr√≥prio, n√£o com frameworks prontos. Isso porque os agentes que realmente entregam valor n√£o s√£o t√£o "agentes" assim, s√£o softwares determin√≠sticos, com chamadas pontuais de LLM nos lugares certos._

Daniel Romiero - AI Engineer | Generative AI, RAG & Agents 

---

...onde comecou a jornada.

# 12-factor-agents

Assim como em determinado tempo os 12 fatores foram a base para o desenvolvimento de aplica√ß√µes web escal√°veis, devido ao crescimento desenfreado eis que surgiram os 12 fatores base para o desenvolvimento de agentes eficazes.

---

### 1. Domine a Convers√£o de Linguagem Natural para Chamada de Ferramenta

A capacidade de transformar solicita√ß√µes em linguagem natural em chamadas de ferramentas estruturadas est√° no cora√ß√£o da funcionalidade do agente. √â isso que permite ao agente pegar um comando como **‚Äúcrie um link de pagamento de R$750 para Terri para o meetup dos IA Tinkerers de fevereiro‚Äù** e convert√™-lo em uma chamada de API devidamente formatada.

---

!["Texto alternativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/110-natural-language-tool-calls.png)

---

Exemplo de saida estruturada.

```json
{
  "function": {
    "name": "create_payment_link",
    "parameters": {
      "amount": 750,
      "customer": "cust_128934ddasf9",
      "product": "prod_8675309",
      "price": "prc_09874329fds",
      "quantity": 1,
      "memo": "Hey Jeff - see below for the payment link for the february ai tinkerers meetup"
    }
  }
}
```

---

A saida estrutura lhe permitira ter mais controles de fluxos customizados.

```python
# The LLM takes natural language and returns a structured object
nextStep = await llm.determineNextStep(
  """
  create a payment link for $750 to Jeff 
  for sponsoring the february AI tinkerers meetup
  """
  )

# Handle the structured output based on its function
if nextStep.function == 'create_payment_link':
    stripe.paymentlinks.create(nextStep.parameters)
    return  # or whatever you want, see below
elif nextStep.function == 'something_else':
    # ... more cases
    pass
else:  # the model didn't call a tool we know about
    # do something else
    pass
```

---

‚úÖ Essa abordagem traz algumas vantagens:

- **Confiabilidade**: menos risco de ‚Äúalucina√ß√£o‚Äù.
- **Seguran√ßa**: o agente s√≥ chama APIs autorizadas.
- **Testabilidade**: f√°cil criar testes automatizados para entradas/sa√≠das.
- **Escalabilidade**: novas ferramentas podem ser plugadas sem mudar a l√≥gica central.

---

> Esse fator √© como transformar o agente de um ‚Äúgerador de texto‚Äù em um **‚Äúorquestrador de a√ß√µes reais**‚Äù.

---

### 2. Tenha Total Dom√≠nio dos Seus Prompts

Seus prompts s√£o a interface entre sua aplica√ß√£o e o modelo de linguagem ‚Äî **trate-os como c√≥digo de primeira classe.** Embora frameworks que abstraem prompts possam parecer convenientes, muitas vezes eles ocultam como as instru√ß√µes s√£o passadas para o LLM, dificultando ou impossibilitando ajustes finos.

---

<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>

![w:640 center](https://hamel.dev/blog/posts/prompt/slap_3.jpeg)

---

!["Texto alternativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/120-own-your-prompts.png)

---

```python
def DetermineNextStep(thread: string) 
-> DoneForNow | ListGitTags | DeployBackend | DeployFrontend | RequestMoreInformation {
  prompt #"
    {{ _.role("system") }}
    
    ... Some Instructions
    
    Always think about what to do first, like:
    - Check current deployment status
    - Verify the deployment tag exists
    - Request approval if needed
    - Deploy to staging before production
    - Monitor deployment progress
    
    {{ _.role("user") }}

    {{ thread }}
    
    What should the next step be?
  "#
}
```

---

‚úÖ Essa abordagem traz algumas vantagens:

- **Confiabilidade**: Controle total para escrever instru√ß√µes precisas sob medida para seu caso de uso.
- **Testabilidade**: Capacidade de criar avalia√ß√µes e testes para prompts como qualquer outro c√≥digo.
- **Manutenabilidade**: Transpar√™ncia para entender exatamente o que o LLM recebe.
- **Observabilidade**: Liberdade para iterar com base em m√©tricas de desempenho.

---

> Esse fator garante que o agente n√£o vire uma ‚Äúcaixa-preta imprevis√≠vel‚Äù ‚Äî o prompt √© c√≥digo, deve ser versionado, testado e auditado como tal.

---

### 3. Projete sua Janela de Contexto de Forma Estrat√©gica

A janela de contexto serve como entrada para o LLM, abrangendo prompts, hist√≥rico de conversas e dados externos. Otimiz√°-la aumenta o desempenho e a efici√™ncia do uso dos tokens.

---

!["Texto alternativo da imagem"](https://raw.githubusercontent.com/humanlayer/12-factor-agents/main/img/220-context-engineering.png)

---

Gerencie a janela de contexto do LLM de forma proativa e intencional.

- Garanta que a janela de contexto contenha apenas informa√ß√µes diretamente relevantes para a tarefa atual.
- Remova dados desnecess√°rios para evitar "deriva de contexto".
- Melhore o desempenho do LLM e reduza o uso de tokens.

---

> Esse fator garante que o agente n√£o desperdice contexto, usando recupera√ß√£o inteligente e resumo de estado.

---

### 4. Implemente Ferramentas com Sa√≠das Estruturadas

No essencial, ferramentas s√£o apenas sa√≠das JSON do LLM que disparam a√ß√µes determin√≠sticas no seu c√≥digo. Isso cria uma separa√ß√£o clara entre a tomada de decis√£o da IA e a l√≥gica de execu√ß√£o.

Defina claramente os esquemas das ferramentas:

---

```python
class ResultadoTarefa(BaseModel):
    tarefa: str
    concluida: bool
    prioridade: int
    data: str | None = None


def inteligencia_estruturada(prompt: str) -> ResultadoTarefa:
    client = OpenAI()
    response = client.responses.parse(
        model="gpt-4o-mini",
        input=[
            {
                "role": "system",
                "content": "Extraia da entrada do usu√°rio uma tarefa, seu status (conclu√≠da ou n√£o), prioridade (1 = baixa, 2 = m√©dia, 3 = alta) e data associada, se houver.",
            },
            {"role": "user", "content": prompt},
        ],
        text_format=ResultadoTarefa,
    )
    return response.output_parsed
```

---

‚úÖ Essa abordagem traz algumas vantagens:

- **Confiabilidade**: elimina parsing fr√°gil de texto.
- **Seguran√ßa**: evita que o agente execute comandos errados.
- **Testabilidade**: f√°cil escrever testes unit√°rios para validar entradas e sa√≠das.
- **Escalabilidade**: m√∫ltiplos agentes/ferramentas falam a mesma ‚Äúl√≠ngua‚Äù (JSON).

---

> Esse fator garante que ferramentas n√£o devolvam ‚Äútexto solto‚Äù, mas sim objetos bem definidos, prontos para integra√ß√£o confi√°vel.

---

### 5. Unifique Execu√ß√£o e Estado de Neg√≥cio

Muitos frameworks de agentes separam o estado de execu√ß√£o (ex: etapa atual de um processo) do estado de neg√≥cio (ex: hist√≥rico de chamadas de ferramentas e seus resultados). Essa separa√ß√£o adiciona complexidade desnecess√°ria.

Em vez disso, armazene todo o estado diretamente na janela de contexto, inferindo o estado de execu√ß√£o a partir da sequ√™ncia de eventos

---

![w:1040 center "Texto alternativo da imagem](https://github.com/humanlayer/12-factor-agents/raw/main/img/155-unify-state-animation.gif)

---

‚úÖ Essa abordagem traz algumas vantagens:

- **Confiabilidade**: evita perda de contexto se o agente cair.
- **Governan√ßa**: auditoria clara do que foi feito.
- **Escalabilidade**: m√∫ltiplos agentes podem cooperar no mesmo fluxo.
- **Resili√™ncia**: agentes podem retomar de onde pararam.

---

> Esse fator garante que o c√©rebro do agente (LLM) e o mundo real (neg√≥cio) estejam sempre sincronizados e audit√°veis.

---

### 6. Projete APIs para Iniciar, Pausar e Retomar

Agentes de n√≠vel de produ√ß√£o precisam se integrar perfeitamente a sistemas externos, pausando para tarefas longas e retomando quando acionados por webhooks ou outros eventos.

Implemente APIs que permitam iniciar, pausar e retomar agentes, com armazenamento de estado robusto entre opera√ß√µes. Isso possibilita:

- Suporte flex√≠vel para fluxos de trabalho ass√≠ncronos
- Integra√ß√£o limpa com webhooks e outros sistemas
- Retomada confi√°vel ap√≥s interrup√ß√µes sem reiniciar

---

!["Texto alternativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/165-pause-resume-animation.gif)

---

‚úÖ Essa abordagem traz algumas vantagens:

- **Observabilidade**: sabe exatamente em que estado cada tarefa est√°.
- **Resili√™ncia**: pausa ou retoma sem perder progresso.
- **Integra√ß√£o**: sistemas externos podem orquestrar agentes de forma confi√°vel.
- **Seguran√ßa**: evita execu√ß√µes paralelas indesejadas.

---

> Esse fator permite que tarefas longas ou agentes complexos sejam totalmente control√°veis via APIs, tornando o sistema previs√≠vel, seguro e audit√°vel.

---

### 7. Habilite Colabora√ß√£o Humana com Chamadas de Ferramenta

Agentes de IA as vezes necessitam de input humano para decis√µes cr√≠ticas ou situa√ß√µes amb√≠guas. Usar chamadas de ferramentas estruturadas torna essa intera√ß√£o fluida:

---

!["Texto alternativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/170-contact-humans-with-tools.png)

---

```python
class Options:
  urgency: Literal["low", "medium", "high"]
  format: Literal["free_text", "yes_no", "multiple_choice"]
  choices: List[str]

# Tool definition for human interaction
class RequestHumanInput:
  intent: "request_human_input"
  question: str
  context: str
  options: Options

# Example usage in the agent loop
if nextStep.intent == 'request_human_input':
  thread.events.append({
    type: 'human_input_requested',
    data: nextStep
  })
  thread_id = await save_state(thread)
  await notify_human(nextStep, thread_id)
  return # Break loop and wait for response to come back with thread ID
```

---

‚úÖ Essa abordagem traz algumas vantagens:

**Seguran√ßa** e conformidade: decis√µes cr√≠ticas passam por revis√£o humana.
**Resili√™ncia**: agente continua workflow mesmo quando precisa de ajuda.
**Rastreabilidade**: hist√≥rico claro de decis√µes e intera√ß√µes.
**Escalabilidade**: humanos podem atuar apenas em pontos cr√≠ticos, agentes cuidam do restante.

---

> O agente deve saber quando envolver humanos, como notificar e como processar a resposta, mantendo todo o fluxo estruturado e audit√°vel.

---

### 8. Controle o Fluxo do Seu Agente
Fluxo de controle personalizado permite pausar para aprova√ß√£o humana, armazenar resultados em cache ou implementar limita√ß√µes de taxa ‚Äî adaptando o comportamento do agente √†s suas necessidades espec√≠ficas.

---

!["Texto alteranativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/180-control-flow.png)

---

```python
async function handleNextStep(thread: Thread) {
  while (true) {
    const nextStep = await determineNextStep(threadToPrompt(thread));
    if (nextStep.intent === 'request_clarification') {
      await sendMessageToHuman(nextStep);
      await db.saveThread(thread);
      break;
    } else if (nextStep.intent === 'fetch_open_issues') {
      const issues = await linearClient.issues();
      thread.events.push({ type: 'fetch_open_issues_result', data: issues });
      continue;
    }
  }
}
```

---

**üí° Tips**

- Execute um ciclo OODA expl√≠cito (Observar-Orientar-Decidir-Agir).
- Use heur√≠sticas de converg√™ncia em vez de prompts aninhados.
- Evite que o LLM gerencie fluxos de controle complexos.

---

### Ciclo OODA

![center "Texto alternativo da imagem"](https://upload.wikimedia.org/wikipedia/commons/3/3a/OODA.Boyd.svg)

---

‚úÖ Essa abordagem traz algumas vantagens:

**Resili√™ncia**: lida com falhas e instabilidades externas.
**Previsibilidade**: comportamento do agente √© determin√≠stico e audit√°vel.
**Seguran√ßa**: evita decis√µes autom√°ticas fora do esperado.
**Escalabilidade**: m√∫ltiplos agentes podem seguir o mesmo fluxo padr√£o.

---

> O agente **n√£o deve depender apenas do modelo para decidir o que fazer**.
Ele precisa de **fluxo de controle expl√≠cito**, com **decis√µes claras, retries, timeouts e fallbacks**, garantindo confiabilidade e previsibilidade.

---

### 9. Compacte erros na Janela de Contexto
Incluir erros diretamente na janela de contexto permite que agentes de IA aprendam com falhas e ajustem sua abordagem.

Modelos de linguagem t√™m limite de tokens, portanto n√£o √© vi√°vel enviar todas as falhas ou logs detalhados no contexto.

---

!["Texto alternativo imagem"](https://github.com/humanlayer/12-factor-agents/blob/main/img/195-factor-9-errors.gif?raw=true)

---

```python
consecutive_errors = 0

while True:

  # ... existing code ...

  try:
    result = await handle_next_step(thread, next_step)
    thread["events"].append({
      "type": next_step.intent + '_result',
      data: result,
    })
    # success! reset the error counter
    consecutive_errors = 0
  except Exception as e:
    consecutive_errors += 1
    if consecutive_errors < 3:
      # do the loop and try again
      thread["events"].append({
        "type": 'error',
        "data": format_error(e),
      })
    else:
      # break the loop, reset parts of the context window, escalate to a human, or whatever else you want to do
      break
  }
}
```

---

**üí° Tips** Compacte as informa√ß√µes de erro no pr√≥ximo prompt para fechar o ciclo de feedback.

- Permita que o LLM aprenda e se recupere de erros.
- Forne√ßa informa√ß√µes de erro estruturadas.
- Suporte a capacidade de autocorre√ß√£o.

---

‚úÖ Essa abordagem traz algumas vantagens:

**Efici√™ncia**: menos tokens = menor custo e resposta mais r√°pida.
**Confiabilidade**: o agente aprende com seus erros e se recupera dos mesmos.
**Observabilidade**: e possivel identificar pontos de falha e ajustar fluxos.
**Escalabilidade**: fluxos longos ou agentes m√∫ltiplos continuam operando sem estourar contexto.

---

> Esse fator garante que o agente n√£o perca contexto relevante e ainda economize tokens, mantendo a confiabilidade mesmo em fluxos longos ou complexos.

---

### 10. Construa Agentes Pequenos e Focados

Agentes pequenos que lidam com 3 a 20 etapas mant√™m janelas de contexto administr√°veis, melhorando o desempenho e a confiabilidade do LLM. Essa abordagem proporciona:

- Clareza com escopo bem definido para cada agente
- Menor risco do agente perder o foco
- Testes e valida√ß√£o mais f√°ceis de fun√ß√µes espec√≠ficas

---

!["Texto alterantivo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/1a0-small-focused-agents.png)

---

```python
# agente_pedidos.py
class AgentePedidos:
    def processar_pedido(self, pedido_id):
        print(f"[AgentePedidos] Processando pedido {pedido_id}")
        return {"pedido_id": pedido_id, "status": "processado"}

# agente_pagamentos.py
class AgentePagamentos:
    def validar_pagamento(self, pedido_id):
        print(f"[AgentePagamentos] Validando pagamento do pedido {pedido_id}")
        return {"pedido_id": pedido_id, "pagamento_valido": True}

# orquestrador.py
from agente_pedidos import AgentePedidos
from agente_pagamentos import AgentePagamentos

class Orquestrador:
    def __init__(self):
        self.agente_pedidos = AgentePedidos()
        self.agente_pagamentos = AgentePagamentos()
    
    def workflow_pedido(self, pedido_id):
        resultado_pagamento = self.agente_pagamentos.validar_pagamento(pedido_id)
        if resultado_pagamento["pagamento_valido"]:
            return self.agente_pedidos.processar_pedido(pedido_id)
        else:
            return {"pedido_id": pedido_id, "status": "falha no pagamento"}

# Uso
orquestrador = Orquestrador()
resultado = orquestrador.workflow_pedido(123)
print("Resultado final:", resultado)
```

---

‚úÖ Essa abordagem traz algumas vantagens:

**Manuten√ß√£o** mais f√°cil: mudan√ßas em um agente n√£o afetam os outros.
**Confiabilidade**: menor chance de erro global.
**Testabilidade**: cada agente tem inputs e outputs bem definidos.
**Flexibilidade**: novos agentes podem ser adicionados sem refatorar o sistema existente.

---

> Cada agente tem uma responsabilidade clara. O orquestrador combina agentes pequenos para formar workflows maiores. Essa abordagem torna o sistema mais modular, test√°vel e escal√°vel.

---

### 11. Habilite Gatilhos de M√∫ltiplas Fontes
Deixe seus agentes acess√≠veis permitindo acionamento por Slack, e-mail ou sistemas de eventos ‚Äî encontrando os usu√°rios onde eles j√° trabalham.

Implemente APIs que iniciam agentes a partir de diversos canais e respondem pelo mesmo meio. Isso permite:

- Melhor acessibilidade ao integrar com plataformas preferidas dos usu√°rios
- Suporte a fluxos de trabalho de automa√ß√£o orientados a eventos
- Workflows de aprova√ß√£o humana para opera√ß√µes cr√≠ticas

---

!["Texto alternativo da imagem"](https://github.com/humanlayer/12-factor-agents/raw/main/img/1b0-trigger-from-anywhere.png)

---

```python
from datetime import datetime

class Evento:
    def __init__(self, tipo, dados, origem):
        self.tipo = tipo
        self.dados = dados
        self.origem = origem
        self.timestamp = datetime.now()

class Agente:
    def processar_evento(self, evento: Evento):
        print(f"[{evento.timestamp}] Evento de {evento.origem} ({evento.tipo}): {evento.dados}")

# Instanciando agente
agente = Agente()

# Eventos vindos de diferentes fontes
evento_api = Evento(tipo="pedido", dados={"pedido_id": 123}, origem="API")
evento_slack = Evento(tipo="aprovacao", dados={"pedido_id": 124}, origem="Slack")
evento_sqs = Evento(tipo="notificacao", dados={"mensagem": "Pagamento pendente"}, origem="SQS")

# Processando eventos
agente.processar_evento(evento_api)
agente.processar_evento(evento_slack)
agente.processar_evento(evento_sqs)
```

---

> O agente se torna reativo a m√∫ltiplas fontes de evento. Facilita integra√ß√£o com sistemas heterog√™neos, aumento de confiabilidade e modularidade no fluxo de decis√µes.

---

### 12. Projete Agentes como Redutores Sem Estado
Trate agentes como fun√ß√µes sem estado que transformam o contexto de entrada em a√ß√µes de sa√≠da, simplificando a gest√£o de estado e tornando-os previs√≠veis e mais f√°ceis de depurar.

---

!["Texto alteranativo da imamge"](https://github.com/humanlayer/12-factor-agents/raw/main/img/1c0-stateless-reducer.png)

---

Um agente n√£o deve armazenar estado interno de longo prazo. Ele deve receber entradas, process√°-las e emitir sa√≠das, sem depender de mem√≥ria pr√≥pria para decis√µes futuras.

O estado de neg√≥cio ou hist√≥rico deve ser armazenado externamente (DB, cache, eventos).

Essa abordagem permite escala horizontal, reexecu√ß√£o e consist√™ncia.

---

‚úÖ Essa abordagem traz algumas vantagens:

**Escalabilidade horizontal**: agentes podem ser replicados facilmente.
**Resili√™ncia:** crash do agente n√£o perde informa√ß√µes.
**Reprodutibilidade:** inputs determinam outputs de forma consistente.
**Simplicidade:** c√≥digo do agente √© mais previs√≠vel e test√°vel.

---

> O agente n√£o mant√©m estado interno, atuando como um reducer: transforma inputs em outputs. Todo estado relevante √© persistido externamente, permitindo escala, reexecu√ß√£o e confiabilidade.

---

### Referencias:

[Twelve Factor Agents](https://github.com/humanlayer/12-factor-agents/tree/main)
[Twelve Factor Agents for Building Effective AI Systems at Scale](https://www.flowhunt.io/pt/blog/the-12-factor-ai-agent-building-effective-ai-systems-that-scale/)
[Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)
[Show me the Prompts](https://hamel.dev/blog/posts/prompt/)

---

![w:740 center "Texto alternativo da imagem"](https://clampettstudio.com/cdn/shop/files/That_sallFolks_1_web.jpg?v=1752108572&width=1445)
